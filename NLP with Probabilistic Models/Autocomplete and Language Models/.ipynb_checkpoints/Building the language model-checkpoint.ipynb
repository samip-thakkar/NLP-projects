{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build language model to predict the next word for autocomplete "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of n-gram ('i', 'am', 'happy'): 2\n",
      "n-gram ('i', 'am', 'learning') missing\n",
      "n-gram ('i', 'am', 'learning') found\n"
     ]
    }
   ],
   "source": [
    "#Calculate the ngram count dictionary\n",
    "n_gram_counts = {\n",
    "    ('i', 'am', 'happy'): 2,\n",
    "    ('am', 'happy', 'because'): 1\n",
    "}\n",
    "\n",
    "#Get the count of n-gram tuple\n",
    "print(f\"Count of n-gram {('i', 'am', 'happy')}: {n_gram_counts[('i', 'am', 'happy')]}\")\n",
    "      \n",
    "#Check if n-gram is present in dictionary\n",
    "if ('i', 'am', 'learning') in n_gram_counts:\n",
    "    print(f\"n-gram {('i', 'am', 'learning')} found\")\n",
    "else:\n",
    "    print(f\"n-gram {('i', 'am', 'learning')} missing\")\n",
    "\n",
    "# update the count in the word count dictionary\n",
    "n_gram_counts[('i', 'am', 'learning')] = 1\n",
    "if ('i', 'am', 'learning') in n_gram_counts:\n",
    "    print(f\"n-gram {('i', 'am', 'learning')} found\")\n",
    "else:\n",
    "    print(f\"n-gram {('i', 'am', 'learning')} missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i', 'am', 'happy', 'because')\n"
     ]
    }
   ],
   "source": [
    "#Create n_gram with concatenating a tuple for prefix and last word\n",
    "prefix = ('i', 'am', 'happy')\n",
    "word = 'because'\n",
    "\n",
    "n_gram = prefix + (word,)\n",
    "print(n_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to create trigram counts\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def calculate_trigram_count_matrix(corpus):\n",
    "    \n",
    "    #Initialize empty matrix for storing bigrams and vocab\n",
    "    bigrams = []\n",
    "    vocabulary = []\n",
    "    #Initialize empty dictionary to store trigram count\n",
    "    count_matrix_d = defaultdict(dict)\n",
    "    \n",
    "    #Iterate through corpus for single pass\n",
    "    for i in range(len(corpus) - 3 + 1):\n",
    "        \n",
    "        #Get the trigram and bigram\n",
    "        trigram = tuple(corpus[i:i + 3])\n",
    "        bigram = trigram[:-1]\n",
    "        \n",
    "        #Check for bigram in list\n",
    "        if bigram not in bigrams:\n",
    "            bigrams.append(bigram)\n",
    "        \n",
    "        #Get the last word of trigram\n",
    "        last_word = trigram[-1]\n",
    "        #Check of last word in vocabulary\n",
    "        if last_word not in vocabulary:\n",
    "            vocabulary.append(last_word)\n",
    "        \n",
    "        #Add the bigram and lastword in count dictionary\n",
    "        if (bigram, last_word) not in count_matrix_d:\n",
    "            count_matrix_d[bigram, last_word] = 1\n",
    "        else:\n",
    "            count_matrix_d[bigram, last_word] += 1\n",
    "        \n",
    "    #Convert the dictionary to numpy array\n",
    "    count_matrix = np.zeros((len(bigrams), len(vocabulary)))\n",
    "\n",
    "    #Fill the matrix from dictionary\n",
    "    for trigram_key, trigram_count in count_matrix_d.items():\n",
    "        count_matrix[bigrams.index(trigram_key[0]), vocabulary.index(trigram_key[1])] = trigram_count\n",
    "\n",
    "    #Convert the matrix to dataframe\n",
    "    count_matrix = pd.DataFrame(count_matrix, index = bigrams, columns = vocabulary)\n",
    "\n",
    "    return bigrams, vocabulary, count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  happy  because    i   am  learning    .\n",
      "(i, am)             1.0      0.0  0.0  0.0       1.0  0.0\n",
      "(am, happy)         0.0      1.0  0.0  0.0       0.0  0.0\n",
      "(happy, because)    0.0      0.0  1.0  0.0       0.0  0.0\n",
      "(because, i)        0.0      0.0  0.0  1.0       0.0  0.0\n",
      "(am, learning)      0.0      0.0  0.0  0.0       0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "#Create a sample corpus\n",
    "corpus = ['i', 'am', 'happy', 'because', 'i', 'am', 'learning', '.']\n",
    "\n",
    "#Get the bigrams, vocabulary and count_matrix\n",
    "bigrams, vocabulary, count_matrix = calculate_trigram_count_matrix(corpus)\n",
    "\n",
    "print(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  happy  because    i   am  learning    .\n",
      "(i, am)             0.5      0.0  0.0  0.0       0.5  0.0\n",
      "(am, happy)         0.0      1.0  0.0  0.0       0.0  0.0\n",
      "(happy, because)    0.0      0.0  1.0  0.0       0.0  0.0\n",
      "(because, i)        0.0      0.0  0.0  1.0       0.0  0.0\n",
      "(am, learning)      0.0      0.0  0.0  0.0       0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "#Convert the count matrix to probability matrix\n",
    "\n",
    "#Get the sum of rows of Dataframe\n",
    "row_sums = count_matrix.sum(axis = 1)\n",
    "\n",
    "#Get the probability matrix\n",
    "prob_matrix = count_matrix / row_sums[:, None]\n",
    "\n",
    "print(prob_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Probability of happy following ('i', 'am') is 0.5\"\n"
     ]
    }
   ],
   "source": [
    "#Find the probability of trigram\n",
    "\n",
    "trigram = ('i', 'am', 'happy')\n",
    "\n",
    "#Get the bigram and word\n",
    "bigram, word = trigram[:-1], trigram[-1]\n",
    "\n",
    "#Get the probability of trigram\n",
    "trigram_probability = prob_matrix[word][bigram]\n",
    "\n",
    "print(f'\"Probability of {word} following {bigram} is {trigram_probability}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words in vocabulary starting with prefix: ha\n",
      "\n",
      "happy\n",
      "have\n"
     ]
    }
   ],
   "source": [
    "#Check if word starts with given word\n",
    "# lists all words in vocabulary starting with a given prefix\n",
    "vocabulary = ['i', 'am', 'happy', 'because', 'learning', '.', 'have', 'you', 'seen','it', '?']\n",
    "starts_with = 'ha'\n",
    "\n",
    "print(f'words in vocabulary starting with prefix: {starts_with}\\n')\n",
    "for word in vocabulary:\n",
    "    if word.startswith(starts_with):\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the data into training, validation and test data\n",
    "import random\n",
    "\n",
    "def training_validation_test_split(data, train_percentage, val_percentage):\n",
    "    \n",
    "    #Fix randomness\n",
    "    random.seed(42)\n",
    "    #Shuffle data\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    #Get the training data\n",
    "    train_size = int(len(data) * train_percentage / 100)\n",
    "    train_data = data[:train_size]\n",
    "    \n",
    "    #Get the validation data\n",
    "    val_size = int(len(data) * val_percentage / 100)\n",
    "    val_data = data[train_size: train_size + val_size]\n",
    "    \n",
    "    #Get the test data\n",
    "    test_data = data[train_size + val_size:]\n",
    "    \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split 80/10/10:\n",
      " train data:[42, 41, 91, 9, 65, 50, 1, 70, 15, 78, 73, 10, 55, 56, 72, 45, 48, 92, 76, 37, 30, 21, 32, 96, 80, 49, 83, 26, 87, 33, 8, 47, 59, 63, 74, 44, 98, 52, 85, 12, 36, 23, 39, 40, 18, 66, 61, 60, 7, 34, 99, 46, 2, 51, 16, 38, 58, 68, 22, 62, 24, 5, 6, 67, 82, 19, 79, 43, 90, 20, 0, 95, 57, 93, 53, 89, 25, 71, 84, 77]\n",
      " validation data:[64, 29, 27, 88, 97, 4, 54, 75, 11, 69]\n",
      " test data:[86, 13, 17, 28, 31, 35, 94, 3, 14, 81]\n",
      "\n",
      "split 98/1/1:\n",
      " train data:[39, 23, 13, 78, 19, 99, 41, 0, 45, 84, 93, 73, 38, 58, 57, 66, 7, 17, 25, 52, 8, 21, 59, 94, 64, 34, 88, 83, 75, 63, 15, 60, 62, 67, 53, 18, 14, 2, 4, 55, 98, 96, 12, 36, 76, 79, 5, 24, 70, 74, 81, 61, 91, 46, 48, 85, 22, 90, 32, 6, 80, 50, 1, 43, 27, 37, 77, 40, 86, 30, 42, 35, 68, 28, 51, 69, 49, 95, 97, 71, 82, 33, 26, 11, 3, 65, 16, 89, 10, 20, 54, 56, 92, 87, 47, 44, 31, 9]\n",
      " validation data:[72]\n",
      " test data:[29]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test the function\n",
    "data = [x for x in range (0, 100)]\n",
    "\n",
    "train_data, validation_data, test_data = training_validation_test_split(data, 80, 10)\n",
    "print(\"split 80/10/10:\\n\",f\"train data:{train_data}\\n\", f\"validation data:{validation_data}\\n\", \n",
    "      f\"test data:{test_data}\\n\")\n",
    "\n",
    "train_data, validation_data, test_data = training_validation_test_split(data, 98, 1)\n",
    "print(\"split 98/1/1:\\n\",f\"train data:{train_data}\\n\", f\"validation data:{validation_data}\\n\", \n",
    "      f\"test data:{test_data}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316.22776601683796\n"
     ]
    }
   ],
   "source": [
    "#Find the perplexity\n",
    "p = 10 ** (-250)\n",
    "M = 100\n",
    "perplexity = p ** (-1 / M)\n",
    "print(perplexity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
