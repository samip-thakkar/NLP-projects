{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tagging can be difficult as a single word can represent various parts of speech at different times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from utils_pos import get_word_tag, preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sources: We use training data and test data along with vocabulary. Training set will be used to create the emission, transmission and tag counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some examples from training corpus: \n",
      "['In\\tIN\\n', 'an\\tDT\\n', 'Oct.\\tNNP\\n', '19\\tCD\\n', 'review\\tNN\\n']\n"
     ]
    }
   ],
   "source": [
    "#Load the training corpus\n",
    "with open('WSJ_02-21.pos', 'r') as f:\n",
    "    training_corpus = f.readlines()\n",
    "\n",
    "print(\"Some examples from training corpus: \")\n",
    "print(training_corpus[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocabulary:  23777\n",
      "Few examples of vacabulary: \n",
      "['!', '#', '$', '%', '&', \"'\", \"''\", \"'40s\", \"'60s\", \"'70s\", \"'80s\", \"'86\", \"'90s\", \"'N\", \"'S\", \"'d\", \"'em\", \"'ll\", \"'m\", \"'n'\", \"'re\", \"'s\", \"'til\", \"'ve\", '(', ')', ',', '-', '--', '--n--', '--unk--', '--unk_adj--', '--unk_adv--', '--unk_digit--', '--unk_noun--', '--unk_punct--', '--unk_upper--', '--unk_verb--', '.', '...', '0.01', '0.0108', '0.02', '0.03', '0.05', '0.1', '0.10', '0.12', '0.13', '0.15']\n",
      "['yards', 'yardstick', 'year', 'year-ago', 'year-before', 'year-earlier', 'year-end', 'year-on-year', 'year-round', 'year-to-date', 'year-to-year', 'yearlong', 'yearly', 'years', 'yeast', 'yelled', 'yelling', 'yellow', 'yen', 'yes', 'yesterday', 'yet', 'yield', 'yielded', 'yielding', 'yields', 'you', 'young', 'younger', 'youngest', 'youngsters', 'your', 'yourself', 'youth', 'youthful', 'yuppie', 'yuppies', 'zero', 'zero-coupon', 'zeroing', 'zeros', 'zinc', 'zip', 'zombie', 'zone', 'zones', 'zoning', '{', '}', '']\n"
     ]
    }
   ],
   "source": [
    "#Get the vocabulary from text file\n",
    "with open('hmm_vocab.txt', 'r') as f:\n",
    "    voc_l = f.read().split('\\n')\n",
    "\n",
    "print(\"Length of vocabulary: \", len(voc_l))\n",
    "print(\"Few examples of vacabulary: \")\n",
    "print(voc_l[:50])\n",
    "print(voc_l[-50:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 elements of vocab dictionary\n",
      ":0\n",
      "!:1\n",
      "#:2\n",
      "$:3\n",
      "%:4\n",
      "&:5\n",
      "':6\n",
      "'':7\n",
      "'40s:8\n"
     ]
    }
   ],
   "source": [
    "#Create a vocabulary dictionary with word as key and index as value after sorting\n",
    "vocab = {}\n",
    "for i, word in enumerate(sorted(voc_l)):\n",
    "    vocab[word] = i\n",
    "\n",
    "#Print first 10 elements of the dictionary\n",
    "print(\"First 10 elements of vocab dictionary\")\n",
    "i = 0\n",
    "for key, val in vocab.items():\n",
    "    print(f\"{key}:{val}\")\n",
    "    i += 1\n",
    "    if i == 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some examples of testing data\n",
      "['The\\tDT\\n', 'economy\\tNN\\n', \"'s\\tPOS\\n\", 'temperature\\tNN\\n', 'will\\tMD\\n']\n"
     ]
    }
   ],
   "source": [
    "#Load the test corpus\n",
    "with open(\"WSJ_24.pos\", 'r') as f:\n",
    "    y = f.readlines()\n",
    "\n",
    "print(\"Some examples of testing data\")\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the preprocessed test corpus:  34199\n",
      "This is a sample of the test_corpus: \n",
      "['The', 'economy', \"'s\", 'temperature', 'will', 'be', 'taken', 'from', 'several', '--unk--']\n"
     ]
    }
   ],
   "source": [
    "#Get the preprocessed corpus (without tags)\n",
    "_, prep = preprocess(vocab, 'test.words')\n",
    "\n",
    "print('The length of the preprocessed test corpus: ', len(prep))\n",
    "print('This is a sample of the test_corpus: ')\n",
    "print(prep[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction based on Start of the Art method (We will word that are not ambiguous)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will create 3 dictionaries: Transition counts: no of times a tag is next to other tag, Emission counts: Probability of occurence of a word given a tag, and Tag counts: counts of a tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to create all the three dictionaries\n",
    "def create_dictionary(training_corpus, vocab):\n",
    "    \n",
    "    #Initialize the three dictionaries\n",
    "    emission_counts = defaultdict(int)\n",
    "    transition_counts = defaultdict(int)\n",
    "    tag_counts = defaultdict(int)\n",
    "    \n",
    "    #Initialize the previous tag with start as --s--\n",
    "    prev_tag = '--s--'\n",
    "    \n",
    "    #Iterator to track the line number in corpus\n",
    "    i = 0\n",
    "    \n",
    "    #Iterate through the training corpus\n",
    "    for word_tag in training_corpus:\n",
    "        \n",
    "        i += 1\n",
    "        if i % 50000 == 0:\n",
    "            print(f\"{i} Words processed\")\n",
    "        \n",
    "        #Get the word and its tag from vocab\n",
    "        word, tag = get_word_tag(word_tag, vocab)\n",
    "        \n",
    "        #Increase the counter of transition, emission and tags dictionaries\n",
    "        transition_counts[(prev_tag, tag)] += 1\n",
    "        emission_counts[(tag, word)] += 1\n",
    "        tag_counts[tag] += 1\n",
    "        \n",
    "        #Set the current tag to prev_tag for next iteration\n",
    "        prev_tag = tag\n",
    "    \n",
    "    #Return all the three dictionaries\n",
    "    return emission_counts, transition_counts, tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 Words processed\n",
      "100000 Words processed\n",
      "150000 Words processed\n",
      "200000 Words processed\n",
      "250000 Words processed\n",
      "300000 Words processed\n",
      "350000 Words processed\n",
      "400000 Words processed\n",
      "450000 Words processed\n",
      "500000 Words processed\n",
      "550000 Words processed\n",
      "600000 Words processed\n",
      "650000 Words processed\n",
      "700000 Words processed\n",
      "750000 Words processed\n",
      "800000 Words processed\n",
      "850000 Words processed\n",
      "900000 Words processed\n",
      "950000 Words processed\n"
     ]
    }
   ],
   "source": [
    "#Populate the dictionaries using out training corpus and vocab\n",
    "emission_counts, transition_counts, tag_counts = create_dictionary(training_corpus, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of POS states:  46\n",
      "POS states:  ['#', '$', \"''\", '(', ')', ',', '--s--', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n"
     ]
    }
   ],
   "source": [
    "#Get all the POS states\n",
    "states = sorted(tag_counts.keys())\n",
    "print(\"Number of POS states: \", len(states))\n",
    "print(\"POS states: \", states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition dictionary examples\n",
      "(('--s--', 'IN'), 5050)\n",
      "(('IN', 'DT'), 32364)\n",
      "(('DT', 'NNP'), 9044)\n",
      "Emission dictionary examples\n",
      "(('IN', 'In'), 1735)\n",
      "(('DT', 'an'), 3142)\n",
      "(('NNP', 'Oct.'), 317)\n",
      "Ambiguous words examples\n",
      "('RB', 'back') 304\n",
      "('VB', 'back') 20\n",
      "('RP', 'back') 84\n",
      "('JJ', 'back') 25\n",
      "('NN', 'back') 29\n",
      "('VBP', 'back') 4\n"
     ]
    }
   ],
   "source": [
    "#View the transition and emission dictionaries sample\n",
    "print(\"Transition dictionary examples\")\n",
    "for ex in list(transition_counts.items())[:3]:\n",
    "    print(ex)\n",
    "\n",
    "print(\"Emission dictionary examples\")\n",
    "for ex in list(emission_counts.items())[:3]:\n",
    "    print(ex)\n",
    "\n",
    "#Print some of the ambiguous words\n",
    "print(\"Ambiguous words examples\")\n",
    "for tupple, count in emission_counts.items():\n",
    "    if tupple[1] == 'back':\n",
    "        print(tupple, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the accuracy of POS tagger using emission_counts dictionary. We will assign the POS tag to each word in test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the function to predict the POS tag\n",
    "def predict_tags(prep, y, emission_counts, vocab, states):\n",
    "    \n",
    "    #y is test data and prep is the preprocessed version of y\n",
    "    #Set the initial number of correct predictions to 0\n",
    "    num_corrects = 0\n",
    "    \n",
    "    #Get all the tuples of emssion_dictionary\n",
    "    all_words = set(emission_counts.keys())\n",
    "    \n",
    "    #Get the length of test data\n",
    "    total = len(y)\n",
    "    \n",
    "    #Iterate over all the test data\n",
    "    for word, y_tup in zip(prep, y):\n",
    "        \n",
    "        #Split the tuple to get word and POS\n",
    "        y_tup_ = y_tup.split()\n",
    "        \n",
    "        #Check if both word and POS is present, if so get the correct POS label\n",
    "        if len(y_tup_) == 2:\n",
    "            correct_label = y_tup_[1]\n",
    "        \n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        #Initialize the pos_tag and count to 0 get the prediction\n",
    "        pos_tag = ''\n",
    "        count_max = 0\n",
    "        \n",
    "        #Check if word in vocab\n",
    "        if word in vocab:\n",
    "            \n",
    "            #Iterate over all states\n",
    "            for pos in states:\n",
    "                \n",
    "                #Get the tupple \n",
    "                key = (pos, word)\n",
    "                \n",
    "                #Check if key is in emission_counts and its count\n",
    "                if key in emission_counts:\n",
    "                    \n",
    "                    counts = emission_counts[key]\n",
    "                    \n",
    "                    #Update predicted pos if count is greater than max_count\n",
    "                    if counts > count_max:\n",
    "                        count_max = counts\n",
    "                        pos_tag = pos\n",
    "        \n",
    "        #Check if pos_tag is same as correct_label\n",
    "        if correct_label == pos_tag:\n",
    "            num_corrects += 1\n",
    "        \n",
    "    #Return the accuracy\n",
    "    accuracy = num_corrects / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy based on emission tags:  0.8888563993099213\n"
     ]
    }
   ],
   "source": [
    "#Get the accuracy of our data\n",
    "accuracy = predict_tags(prep, y, emission_counts, vocab, states)\n",
    "print(\"Accuracy based on emission tags: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We got 88.89% accuracy by State of Art Method, we will now try with Hidden Markov Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Models for context based prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use transition matrix (A), emission matrix (B) and states (POS tag of word) in Hidden Markov Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate matrices transition matrix (A) (alpha is used for smoothing)\n",
    "\n",
    "def create_transition_matrix(alpha, tag_counts, transition_counts):\n",
    "    \n",
    "    #Get the sorted order of POS tags\n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    #Get the length of the unique tags\n",
    "    num_tags = len(all_tags)\n",
    "    \n",
    "    #Initialize transition matrix with zeros\n",
    "    A = np.zeros((num_tags, num_tags))\n",
    "    \n",
    "    #Get the unique transition tuples (prev POS, cur POS)\n",
    "    transition_keys = set(transition_counts.keys())\n",
    "    \n",
    "    #Iterate over all rows and columns of transition matrix\n",
    "    for i in range(num_tags):\n",
    "        for j in range(num_tags):\n",
    "            \n",
    "            #Initialize the counts to 0\n",
    "            counts = 0\n",
    "            \n",
    "            #Get the tuple of row, col as key\n",
    "            key = (all_tags[i], all_tags[j])\n",
    "            \n",
    "            #Check if key is in transition keys\n",
    "            if key in transition_keys:\n",
    "                \n",
    "                #Get the count from transition counts\n",
    "                counts = transition_counts[key]\n",
    "            \n",
    "            #Get the total counts of previous tags\n",
    "            prev_tags_count = tag_counts[all_tags[i]]\n",
    "            \n",
    "            #Populate the transition matrix \n",
    "            A[i, j] = (counts + alpha) / (prev_tags_count + alpha * num_tags)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View a subset of transition matrix A\n",
      "              RBS            RP           SYM        TO            UH\n",
      "RBS  2.217069e-06  2.217069e-06  2.217069e-06  0.008870  2.217069e-06\n",
      "RP   3.756509e-07  7.516775e-04  3.756509e-07  0.051089  3.756509e-07\n",
      "SYM  1.722772e-05  1.722772e-05  1.722772e-05  0.000017  1.722772e-05\n",
      "TO   4.477336e-05  4.472863e-08  4.472863e-08  0.000090  4.477336e-05\n",
      "UH   1.030439e-05  1.030439e-05  1.030439e-05  0.061837  3.092348e-02\n"
     ]
    }
   ],
   "source": [
    "#Create a transition matrix with alpha = 0.001\n",
    "alpha = 0.001\n",
    "A = create_transition_matrix(alpha, tag_counts, transition_counts)\n",
    "\n",
    "print(\"View a subset of transition matrix A\")\n",
    "A_sub = pd.DataFrame(A[30:35,30:35], index=states[30:35], columns = states[30:35] )\n",
    "print(A_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to create emission matrix (occurence of tag and word pair)\n",
    "def create_emission_matrix(alpha, tag_counts, emission_counts, vocab):\n",
    "    \n",
    "    #Get the number of POS tags\n",
    "    num_tags = len(tag_counts)\n",
    "    #Get the list of all tags\n",
    "    all_tags = sorted(tag_counts.keys())\n",
    "    #Get the total number of words in vocabulory\n",
    "    num_words = len(vocab)\n",
    "    \n",
    "    #Initialize the emission matrix\n",
    "    B = np.zeros((num_tags, num_words))\n",
    "    \n",
    "    #Get the set of (POS, word) tuples from emission_counts\n",
    "    emission_keys = set(list(emission_counts.keys()))\n",
    "    \n",
    "    #Iterate through all elements of Emission matrix and populate them\n",
    "    for i in range(num_tags):\n",
    "        for j in range(num_words):\n",
    "            \n",
    "            count = 0\n",
    "            \n",
    "            key = (all_tags[i], vocab[j])\n",
    "            if key in emission_keys:\n",
    "                count = emission_counts[key]\n",
    "            \n",
    "            tag_count = tag_counts[all_tags[i]]\n",
    "            \n",
    "            B[i, j] = (count + alpha) / (tag_count + alpha * num_words)\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View Matrix position at row 0, column 0: 0.000006032\n",
      "View Matrix position at row 3, column 1: 0.000000720\n",
      "              725      adroitly     engineers      promoted       synergy\n",
      "CD   8.201296e-05  2.732854e-08  2.732854e-08  2.732854e-08  2.732854e-08\n",
      "NN   7.521128e-09  7.521128e-09  7.521128e-09  7.521128e-09  2.257091e-05\n",
      "NNS  1.670013e-08  1.670013e-08  4.676203e-04  1.670013e-08  1.670013e-08\n",
      "VB   3.779036e-08  3.779036e-08  3.779036e-08  3.779036e-08  3.779036e-08\n",
      "RB   3.226454e-08  6.456135e-05  3.226454e-08  3.226454e-08  3.226454e-08\n",
      "RP   3.723317e-07  3.723317e-07  3.723317e-07  3.723317e-07  3.723317e-07\n"
     ]
    }
   ],
   "source": [
    "#Create emission matrix with alpha as 0.001\n",
    "alpha = 0.001\n",
    "B = create_emission_matrix(alpha, tag_counts, emission_counts, list(vocab))\n",
    "\n",
    "print(f\"View Matrix position at row 0, column 0: {B[0,0]:.9f}\")\n",
    "print(f\"View Matrix position at row 3, column 1: {B[3,1]:.9f}\")\n",
    "\n",
    "# Try viewing emissions for a few words in a sample dataframe\n",
    "cidx  = ['725','adroitly','engineers', 'promoted', 'synergy']\n",
    "\n",
    "# Get the integer ID for each word\n",
    "cols = [vocab[a] for a in cidx]\n",
    "\n",
    "# Choose POS tags to show in a sample dataframe\n",
    "rvals =['CD','NN','NNS', 'VB','RB','RP']\n",
    "\n",
    "# For each POS tag, get the row number from the 'states' list\n",
    "rows = [states.index(a) for a in rvals]\n",
    "\n",
    "# Get the emissions for the sample of words, and the sample of POS tags\n",
    "B_sub = pd.DataFrame(B[np.ix_(rows,cols)], index=rvals, columns = cidx )\n",
    "print(B_sub)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi Algorithm and Dynamic Programming for POS tag prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization phase: Initialize the best_paths and best_probabilities matrices for forward step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to initialize the best_prob and best_path matrices \n",
    "def viterbi_initialize(states, tag_counts, A, B, corpus, vocab):     # Corpus: sequence of words whose POS is to be predicted\n",
    "    \n",
    "    #Count the number of possible tags\n",
    "    num_tags = len(tag_counts)\n",
    "    \n",
    "    #Initialize best_prob and best_path matrices\n",
    "    best_prob = np.zeros((num_tags, len(corpus)))\n",
    "    best_paths = np.zeros((num_tags, len(corpus)), dtype = int)\n",
    "    \n",
    "    #Define the start token\n",
    "    s_idx = states.index('--s--')\n",
    "    \n",
    "    #Iterate through all the tags\n",
    "    for i in range(num_tags):\n",
    "        \n",
    "        #Set the probability from start to -inf if there is no transition from start to POS index 'i'\n",
    "        if A[s_idx, i] == 0:\n",
    "            best_prob[i, 0] = float('-inf')\n",
    "        \n",
    "        #Else use log summation (prob of reaching A to POS i and prob of POS i to word)\n",
    "        else:\n",
    "            best_prob[i, 0] = math.log(A[s_idx, i]) + math.log(B[i, vocab[corpus[0]]])\n",
    "    return best_prob, best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-22.60982633   0.           0.         ...   0.           0.\n",
      "    0.        ]\n",
      " [-23.07660654   0.           0.         ...   0.           0.\n",
      "    0.        ]\n",
      " [-23.57298822   0.           0.         ...   0.           0.\n",
      "    0.        ]\n",
      " ...\n",
      " [-22.75551606   0.           0.         ...   0.           0.\n",
      "    0.        ]\n",
      " [-19.6637215    0.           0.         ...   0.           0.\n",
      "    0.        ]\n",
      " [-18.36288463   0.           0.         ...   0.           0.\n",
      "    0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Initialize best_probs and best_paths using function\n",
    "best_prob, best_paths = viterbi_initialize(states, tag_counts, A, B, prep, vocab)\n",
    "print(best_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_prob[0,0]: -22.6098\n",
      "best_paths[2,3]: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "print(f\"best_prob[0,0]: {best_prob[0,0]:.4f}\") \n",
    "print(f\"best_paths[2,3]: {best_paths[2,3]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward phase: Populate best_prob and best_path by forward walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function for forward pass of Viterbi algorithm\n",
    "def viterbi_forward(A, B, test_corpus, best_prob, best_paths, vocab):\n",
    "    \n",
    "    #Get the no of unique POS tags\n",
    "    num_tags = best_prob.shape[0]\n",
    "    \n",
    "    #Iterate through all the words in test_corpus starting from 1 (starting word set in initialization phase)\n",
    "    for i in range(1, len(test_corpus)):\n",
    "        \n",
    "        if i % 5000 == 0:\n",
    "            print(\"Words processed: \", i)\n",
    "            \n",
    "        #Iterate through all the tags\n",
    "        for j in range(num_tags):\n",
    "            \n",
    "            #Initialize the best_prob and best_path of word i to -inf and None\n",
    "            best_prob_i = float('-inf')\n",
    "            best_path_i = None\n",
    "            \n",
    "            #Iterate for each tag a previous tag can be\n",
    "            for k in range(num_tags):\n",
    "                \n",
    "                #Get the probability for k from i - 1\n",
    "                prob = best_prob[k, i - 1] + math.log(A[k, j]) + math.log(B[j, vocab[test_corpus[i]]])\n",
    "                \n",
    "                if prob > best_prob_i:\n",
    "                    best_prob_i = prob\n",
    "                    best_path_i = k\n",
    "            best_prob[j, i] = best_prob_i\n",
    "            best_paths[j, i] = best_path_i\n",
    "    return best_prob, best_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words processed:  5000\n",
      "Words processed:  10000\n",
      "Words processed:  15000\n",
      "Words processed:  20000\n",
      "Words processed:  25000\n"
     ]
    }
   ],
   "source": [
    "#Populate the best_prob and best_paths using function\n",
    "best_prob, best_paths = viterbi_forward(A, B, prep, best_prob, best_paths, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test this function \n",
    "print(f\"best_prob[0,1]: {best_prob[0,1]:.4f}\") \n",
    "print(f\"best_prob[0,4]: {best_prob[0,4]:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward phase: Get prediction of POS tag for each word using best_prob and best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to perform backward phase of Viterbi algorithm\n",
    "def viterbi_backward(best_prob, best_paths, corpus, states):\n",
    "    \n",
    "    #Get the number of words in corpus\n",
    "    num_words = best_paths.shape[1]\n",
    "    \n",
    "    #Initialize array with same length to store the result (POS number)\n",
    "    z = [None] * num_words\n",
    "    \n",
    "    #Get the number of unique POS tags\n",
    "    num_tags = best_prob.shape[0]\n",
    "    \n",
    "    #Initialize the best probability for last word to -inf\n",
    "    best_prob_last_word = float('-inf')\n",
    "    \n",
    "    #Initialize array to store results (POS tag)\n",
    "    pred = [None] * num_words\n",
    "    \n",
    "    #Iterate through each tag for last word\n",
    "    for i in range(num_tags):\n",
    "        \n",
    "        #Check the probability for each tag from best_prob matrix\n",
    "        if best_prob[i, num_words - 1] > best_prob_last_word:\n",
    "            best_prob_last_word = best_prob[i, num_words - 1]\n",
    "            \n",
    "            #Set the result to index of POS tag\n",
    "            z[num_words - 1] = i\n",
    "            \n",
    "    #Set the result to state of best POS tag\n",
    "    pred[num_words - 1] = states[z[num_words - 1]]\n",
    "    \n",
    "    #Iterate backwards from last word to first word\n",
    "    for i in range(num_words - 1, -1, -1):\n",
    "        \n",
    "        #Get the result POS tag for word i\n",
    "        pos_tag_i = z[i]\n",
    "        \n",
    "        #Get the best path for i - 1 word\n",
    "        z[i - 1] = best_paths[pos_tag_i, i]\n",
    "        \n",
    "        #Get the corresponding state\n",
    "        pred[i - 1] = states[z[i - 1]]\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and test your function\n",
    "pred = viterbi_backward(best_prob, best_paths, prep, states)\n",
    "m=len(pred)\n",
    "print('The prediction for pred[-7:m-1] is: \\n', prep[-7:m-1], \"\\n\", pred[-7:m-1], \"\\n\")\n",
    "print('The prediction for pred[0:8] is: \\n', pred[0:7], \"\\n\", prep[0:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The third word is:', prep[3])\n",
    "print('Your prediction is:', pred[3])\n",
    "print('Your corresponding label y is: ', y[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the function to predict using viterbi algorithm and calculate the accuracy\n",
    "def calculate_accuracy(pred, y):\n",
    "    \n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for y_pred, y_test in zip(pred, y):\n",
    "        word_tag_tuple = y_test.split()\n",
    "        \n",
    "        if len(word_tag_tuple) != 2:\n",
    "            continue\n",
    "        word, tag = word_tag_tuple\n",
    "        \n",
    "        if tag == y_pred:\n",
    "            num_correct += 1\n",
    "        total += 1\n",
    "    accuracy = num_correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy of the Viterbi algorithm is {calculate_accuracy(pred, y):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy of SOTA: 88.89% and Viterbi algorithm: 95.31%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
